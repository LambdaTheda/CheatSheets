{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "T apr 7 PT5 DS U2 S2 M1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZW91zAXQhT6B",
        "3gSKVMJjhT6N",
        "X68B66nAbIHS",
        "7EQOYZtqr00F",
        "YoMKPfoAhT6U",
        "ElWpiefehT6V",
        "e5tupFXLjj6B",
        "shPLlqdShT6j",
        "ozIRICythT6k",
        "15U76WEzhT6o",
        "h-Bpke-FhT6p",
        "DTORvlCvhT6q",
        "kMW9JbD6wZ28",
        "0s7t37euwd41",
        "yD31msBkwlVQ",
        "jFvsu2onNXw7",
        "lJZSMvW7Nd97",
        "wdjg7U_jNlJG",
        "5zlKegIZBbGr",
        "Tr-83jOEBsxK",
        "MjLGrZjfFGD-",
        "WBQJB0PVFtIE",
        "cH8IVe6GGAsm",
        "q7AASlWVGMD4",
        "MZkaOREUGzYp",
        "rh7ZJe7GHCSp",
        "9KIVsFO_HSmS"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LambdaTheda/CheatSheets/blob/master/T_apr_7_PT5_DS_U2_S2_M1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bs7Tr4Ubw35c"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QX0jgn6FTo2I"
      },
      "source": [
        "# Decision Trees\n",
        "\n",
        "- clean data with **outliers and missing values**\n",
        "- use scikit-learn **pipelines**\n",
        "- use scikit-learn for **decision trees**\n",
        "- get and interpret **feature importances** of a tree-based model\n",
        "- understand why decision trees are useful to model **non-linear, non-monotonic** relationships and **feature interactions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u14XI47bFZTk"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries\n",
        "\n",
        "- **category_encoders** \n",
        "- **graphviz**\n",
        "- ipywidgets\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- **plotly**\n",
        "- seaborn\n",
        "- scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OzeMxiloFV2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81137b80-70a3-417b-f05f-0f92bf9a21d9"
      },
      "source": [
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders==2.*) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n",
            "Collecting pandas-profiling==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/b0/bd5e3aaf37302fbe581b6947dc5ec1cda02a0ffe50fc823123def73e4d7a/pandas-profiling-2.5.0.tar.gz (192kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.18.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.4.1)\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.4MB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (3.2.1)\n",
            "Collecting confuse==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: jinja2==2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (2.11.1)\n",
            "Collecting visions==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/07/4a/ab37f8bafda516b66c4f475b221a6c170097c0db203750a4aafb01023339/visions-0.2.2.tar.gz\n",
            "Collecting htmlmin==0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Requirement already satisfied: missingno==0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.4.2)\n",
            "Collecting phik==0.9.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/cf/b8cef2778104dc5d319f36dd836efaceb07a037cbf63f27c966b5a193ce9/phik-0.9.9-py3-none-any.whl (607kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astropy>=3.2.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (4.0.1.post1)\n",
            "Collecting tangled-up-in-unicode==0.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/fc/e3c970c5007b405827a4623e70fc4eb966ee49bc1edbd56c33e85e1c6534/tangled_up_in_unicode-0.0.3.tar.gz (1.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 42.7MB/s \n",
            "\u001b[?25hCollecting tqdm==4.42.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/2e/4307206db63f05ed37e21d4c0d843d0fbcacd62479f8ce99ba0f2c0875e0/tqdm-4.42.0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle==1.5.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.5.6)\n",
            "Requirement already satisfied: ipywidgets==7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (7.5.1)\n",
            "Collecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->pandas-profiling==2.*) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->pandas-profiling==2.*) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (0.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse==1.0.0->pandas-profiling==2.*) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2==2.11.1->pandas-profiling==2.*) (1.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from visions==0.2.2->pandas-profiling==2.*) (2.4)\n",
            "Collecting attr\n",
            "  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno==0.4.2->pandas-profiling==2.*) (0.10.0)\n",
            "Collecting pytest>=4.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e2/c19c667f42f72716a7d03e8dd4d6f63f47d39feadd44cc1ee7ca3089862c/pytest-5.4.1-py3-none-any.whl (246kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 44.0MB/s \n",
            "\u001b[?25hCollecting pytest-pylint>=0.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/31/ef/e848f832a596a8a40b32d8aa169788b4df167c2d6a5960c01e83a30ebaa7/pytest_pylint-0.15.1-py3-none-any.whl\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (0.48.0)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (0.14.1)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (5.3.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (1.24.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (5.0.5)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (4.10.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->pandas-profiling==2.*) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->pandas-profiling==2.*) (3.0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->visions==0.2.2->pandas-profiling==2.*) (4.4.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (8.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (0.1.9)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (20.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (19.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (1.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (1.8.1)\n",
            "Collecting pylint>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/59/43fc36c5ee316bb9aeb7cf5329cdbdca89e5749c34d5602753827c0aa2dc/pylint-2.4.4-py3-none-any.whl (302kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik==0.9.9->pandas-profiling==2.*) (46.1.3)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik==0.9.9->pandas-profiling==2.*) (0.31.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas-profiling==2.*) (19.0.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas-profiling==2.*) (4.5.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6->pandas-profiling==2.*) (1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas-profiling==2.*) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas-profiling==2.*) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas-profiling==2.*) (5.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (3.1.0)\n",
            "Collecting astroid<2.4,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ae/86734823047962e7b8c8529186a1ac4a7ca19aaf1aa0c7713c022ef593fd/astroid-2.3.3-py3-none-any.whl (205kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215kB 18.5MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas-profiling==2.*) (0.8.3)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 747kB 39.0MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.3MB/s \n",
            "\u001b[?25hCollecting wrapt==1.11.*\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Building wheels for collected packages: pandas-profiling, confuse, visions, htmlmin, tangled-up-in-unicode, attr, wrapt\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.5.0-py2.py3-none-any.whl size=241329 sha256=0873dadcaacd941a88b10499721a7607746e30202b86fab9ad209cb96a9edcad\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/c9/f1/4a2f30c760e017f3e2f46be999c4597a93d126ef5ea38e276f\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17487 sha256=f3842f9ec61dc691e58deebb9c140a9bd4a87b4412d5feb69fd2a2339f4747ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "  Building wheel for visions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visions: filename=visions-0.2.2-cp36-none-any.whl size=53058 sha256=4eef77d466234245b960f018da48af21e4d7de260b880c9eef89f49a88e8c28a\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/87/68/294a9e88d82e395b38571df18f7cb71e9ab51cedae77dd6f31\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=a572a35a66a7f95ef761cac39d6a543876f327e747158f5d0109df632142ab88\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for tangled-up-in-unicode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tangled-up-in-unicode: filename=tangled_up_in_unicode-0.0.3-cp36-none-any.whl size=1554154 sha256=a314f213e7b8c48a81f99a3be573703d2980ae50409fff21c62fb237a7adbe21\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/57/cc/5f58206efb00418d4dcae8d08a3cb40627778ea29622f664c6\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-cp36-none-any.whl size=2459 sha256=06f137b771722924a71679f2c12bd0ab6f6c2fc35fdac45aeeb840e03507a783\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=67516 sha256=e7b9a6a242889f71d297fb849f54de6e702870ee8f0cfd26b31d959253a31db7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "Successfully built pandas-profiling confuse visions htmlmin tangled-up-in-unicode attr wrapt\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas, confuse, tangled-up-in-unicode, attr, visions, htmlmin, pluggy, pytest, typed-ast, lazy-object-proxy, wrapt, astroid, mccabe, isort, pylint, pytest-pylint, phik, tqdm, requests, pandas-profiling\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: tqdm 4.38.0\n",
            "    Uninstalling tqdm-4.38.0:\n",
            "      Successfully uninstalled tqdm-4.38.0\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.3.3 attr-0.3.1 confuse-1.0.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.3 mccabe-0.6.1 pandas-0.25.3 pandas-profiling-2.5.0 phik-0.9.9 pluggy-0.13.1 pylint-2.4.4 pytest-5.4.1 pytest-pylint-0.15.1 requests-2.22.0 tangled-up-in-unicode-0.0.3 tqdm-4.42.0 typed-ast-1.4.1 visions-0.2.2 wrapt-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UFGmW4ijn4YN"
      },
      "source": [
        "# Clean data with outliers and missing values ðŸš°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I76SriaOhT4e",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVg43a4hT4f",
        "colab_type": "text"
      },
      "source": [
        "Real-world data is often dirty. [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide) is a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the common issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "\n",
        "This is true of the Tanzania Waterpumps data, which we'll use throughout your Kaggle Challenge sprint:\n",
        "\n",
        "> Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
        "\n",
        "\n",
        "The Tanzania Waterpumps data has outliers and missing values. Let's start to clean it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yVpWy6fJyTYo"
      },
      "source": [
        "First, load & split data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg8hVHaJTldG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70a93d54-8b0f-4cec-801e-c97f420b312f"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 41), (11880, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWUAQfHvhT4q",
        "colab_type": "text"
      },
      "source": [
        "This is a multi-class classification problem. The majority class occurs with 54% frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDooBI01hT4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ce862763-b642-490f-9bee-7dfb4bf31acc"
      },
      "source": [
        "train['status_group'].value_counts(normalize=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543077\n",
              "non functional             0.384238\n",
              "functional needs repair    0.072685\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5FqGNiRhT4x",
        "colab_type": "text"
      },
      "source": [
        "One common issues is [\"zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "\n",
        "We can use [Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling) to get a report, with warnings about frequent zeros, and much more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aekxX1uhT48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "2b30d21c-904c-4da4-ce91-2c0400976e8d"
      },
      "source": [
        "# Check Pandas Profiling version\n",
        "import pandas_profiling\n",
        "pandas_profiling.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aeff57c7108b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config_minimal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/controller/pandas_decorator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_report_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/model/describe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmissing_dendrogram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_pairwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/visualisation/plot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mregister_matplotlib_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pandas_profiling.mplstyle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/plotting/_misc.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mderegister_matplotlib_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWa_69BthT5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Old code for Pandas Profiling version 2.3\n",
        "# It can be very slow with medium & large datasets.\n",
        "# These parameters will make it faster.\n",
        "\n",
        "# profile = train.profile_report(\n",
        "#     check_correlation_pearson=False,\n",
        "#     correlations={\n",
        "#         'pearson': False,\n",
        "#         'spearman': False,\n",
        "#         'kendall': False,\n",
        "#         'phi_k': False,\n",
        "#         'cramers': False,\n",
        "#         'recoded': False,\n",
        "#     },\n",
        "#     plot={'histogram': {'bayesian_blocks_bins': False}},\n",
        "# )\n",
        "#\n",
        "\n",
        "# New code for Pandas Profiling version 2.4\n",
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "\n",
        "profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DeIQ1lDmqAHY"
      },
      "source": [
        "Note that longitude has 3% zeros. Some of the locations are at [\"Null Island\"](https://en.wikipedia.org/wiki/Null_Island) instead of Tanzania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOetSBQIHX3I",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "px.scatter(train, x='longitude', y='latitude', color='status_group', opacity=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FtWg_yIbyOsJ"
      },
      "source": [
        "The latitude is approximately zero, but not exactly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aP_SmUYzbUuP",
        "colab": {}
      },
      "source": [
        "train[['longitude', 'latitude']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_izRx8FUhT5d",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V-OOtTMzqkhM"
      },
      "source": [
        "#### Define a function to wrangle train, validate, and test sets in the same way.\n",
        "\n",
        "Fix the location, and do more data cleaning and feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QwOx78FgHxHp",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['longitude', 'latitude']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "            \n",
        "    # quantity & quantity_group are duplicates, so drop one\n",
        "    X = X.drop(columns='quantity_group')\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sMqlStuWqwde"
      },
      "source": [
        "Now the locations look better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OEYMZvdY0-X",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "px.scatter(train, x='longitude', y='latitude', color='status_group', opacity=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSOF7clsY23F"
      },
      "source": [
        "By the way, you can also make maps wiith Plotly Express. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dbdljEmCVpf0",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# https://plot.ly/python/mapbox-layers/#base-maps-in-layoutmapboxstyle\n",
        "fig = px.scatter_mapbox(train, lat='latitude', lon='longitude', color='status_group', opacity=0.1)\n",
        "fig.update_layout(mapbox_style='stamen-terrain')\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ypjt052Lrmgn"
      },
      "source": [
        "#### Select features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "666FUbXOXgL8",
        "colab": {}
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target & id\n",
        "train_features = train.drop(columns=[target, 'id']) #id is useless bc high cardinality; ea pupmp has unique id\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50 ; HIGH CARDINATLY PROPORTIONAL TO DATASET SIZE; 50 HERE WAS RANDOMLY CHOSEN\n",
        "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "\n",
        "# Combine the lists \n",
        "features = numeric_features + categorical_features\n",
        "print(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4nWGAs5BWb1t",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW91zAXQhT6B",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "For your Kaggle Challenge, define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. \n",
        "\n",
        "(For example, what other columns have zeros and shouldn't? What other columns are duplicates, or nearly duplicates? Can you extract the year from date_recorded? Can you engineer new features, such as the number of years from waterpump construction to waterpump inspection?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "moC9WikFrqJV"
      },
      "source": [
        "# Use scikit-learn pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWhrFeB0hT6D",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhzaYB_5hT6E",
        "colab_type": "text"
      },
      "source": [
        "We can combine steps with pipelines: Encode, Impute, Scale, Fit, Predict!\n",
        "\n",
        "[The Scikit-Learn User Guide explains why pipelines are useful](https://scikit-learn.org/stable/modules/compose.html), and demonstrates how to use them.\n",
        "\n",
        "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PjRahqVMbDjz"
      },
      "source": [
        "#### Just for comparison's sake, here's preprocessing + Logistic Regression _without_ using a pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eyy2iYhCdRah"
      },
      "source": [
        "Here's the documentation for each step in the process:\n",
        "\n",
        "- https://contrib.scikit-learn.org/categorical-encoding/onehot.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zcT3gcE0aKai",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "imputer = SimpleImputer()\n",
        "scaler = StandardScaler()\n",
        "model = LogisticRegression(multi_class='auto', solver='lbfgs', n_jobs=-1)\n",
        "\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))\n",
        "\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "X_test_imputed = imputer.transform(X_test_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "y_pred = model.predict(X_test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gSKVMJjhT6N",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X68B66nAbIHS"
      },
      "source": [
        "#### Pipelines can help you write more concise code with fewer errors!\n",
        "\n",
        "Let's rewrite the code cell above, but with a pipeline.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ntflqYdszSa-",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7EQOYZtqr00F"
      },
      "source": [
        "#### Get and plot coefficients\n",
        "\n",
        "This is slightly harder when using pipelines.\n",
        "\n",
        "The pipeline doesn't have a `.coef_` attribute. But the model inside the pipeline does. \n",
        "\n",
        "So, here's [how to access steps inside a pipeline](https://scikit-learn.org/stable/modules/compose.html#accessing-steps):\n",
        "\n",
        "> Pipelineâ€™s `named_steps` attribute allows accessing steps by name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RFlfjFN1gyjI",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = pipeline.named_steps['logisticregression']\n",
        "encoder = pipeline.named_steps['onehotencoder']\n",
        "encoded_columns = encoder.transform(X_val).columns\n",
        "coefficients = pd.Series(model.coef_[0], encoded_columns)\n",
        "plt.figure(figsize=(10,30))\n",
        "coefficients.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoMKPfoAhT6U",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "For your assignment, try to use a scikit-learn pipeline. Do you consider it more convenient?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3_J_Imz96wPl"
      },
      "source": [
        "# Use scikit-learn for decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElWpiefehT6V",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this Unit, we learn about two \"families\" or types of models: Linear Models, and Trees.\n",
        "\n",
        "We'll start today with using [Decision Trees](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/), then understanding how they work. (See the Sources heading at the bottom of the notebook for lots of great links!)\n",
        "\n",
        "Later, we'll learn about Random Forests, and Gradient Boosted Trees, which are \"ensemble\" models made of many trees. In practice, these \"Tree Ensembles\" are used more often than a single Decision Tree. \n",
        "\n",
        "But we start with a single Tree because it's a helpful prerequisite for understanding Tree Ensembles. Also, a single, shallow decision tree is a useful baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAzw4-WchT6V",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "86L3lownYE-e"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "We will start with default parameters, including:\n",
        "- `max_depth=None`\n",
        "- `min_samples_leaf=1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-1_grdR-AVyJ",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e5tupFXLjj6B"
      },
      "source": [
        "### Plot the decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jA1SmBwi6H1R",
        "colab": {}
      },
      "source": [
        "# Plot tree\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "model = pipeline.named_steps['decisiontreeclassifier']\n",
        "encoder = pipeline.named_steps['onehotencoder']\n",
        "encoded_columns = encoder.transform(X_val).columns\n",
        "\n",
        "dot_data = export_graphviz(model, \n",
        "                           out_file=None, \n",
        "                           max_depth=3, \n",
        "                           feature_names=encoded_columns,\n",
        "                           class_names=model.classes_, \n",
        "                           impurity=False, \n",
        "                           filled=True, \n",
        "                           proportion=True, \n",
        "                           rounded=True)   \n",
        "display(graphviz.Source(dot_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZYdLLQoMcXp"
      },
      "source": [
        "### Reduce complexity of the decision tree\n",
        "\n",
        "We can use the `min_samples_leaf` parameter to reduce model complexity.\n",
        "\n",
        "It's explained in [scikit-learn docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "Also in [A Visual Introduction to Machine Learning, Part 2](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/):\n",
        "\n",
        "> Models can be adjusted to change the way they fit the data. These 'settings' are called [hyper]parameters. An example of a decision-tree [hyper]parameter is the _minimum node size,_ which regulates the creation of new splits. A node will not split if the number of data points it contains is below the minimum node size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uGv9jYsmgSr6",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shPLlqdShT6j",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Fit a Decision Tree classifier to make new submissions for your Kaggle challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cUW3dabWAWPk"
      },
      "source": [
        "# Get and interpret feature importances of a tree-based model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozIRICythT6k",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Linear models have coefficients, but trees don't. Instead, they have \"feature importances.\"\n",
        "\n",
        "Feature importances are always positive numbers, they don't have a sign. Feature importance measures how early & often a feature is used for the tree's \"branching\" decisions. \n",
        "\n",
        "Like most predictive modeling tools and techniques, feature importances are useful, but have tradeoffs, make assumptions, and can be misinterpreted. We'll continue to discuss through this lesson and the unit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DysirzHBhT6l",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2dSAxgO9sLsx"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVJcNKY_sso-",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15U76WEzhT6o",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "For your assignment, get and plot your feature importances. What features are most important in your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KkV4TjcNAPzp"
      },
      "source": [
        "# Understand why decision trees are useful to model non-linear, non-monotonic relationships and feature interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-Bpke-FhT6p",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTORvlCvhT6q",
        "colab_type": "text"
      },
      "source": [
        "#### What does _(non)monotonic_ mean?!?!\n",
        "- See Figures 1-3 in Wikipedia's article, [Monotonic function](https://en.wikipedia.org/wiki/Monotonic_function)\n",
        "- See [World Population Growth, 1700-2010](https://ourworldindata.org/world-population-growth-past-future). World Population is non-linear and monotonic. Annual growth rate is non-linear and non-monotonic.\n",
        "- See [Accidents per Mile Driven, by Driver Age](http://howwedrive.com/2009/02/20/whats-the-real-risk-of-older-drivers/). This is non-linear and non-monotonic.\n",
        "\n",
        "#### What does _feature interactions_ mean?!?!\n",
        "- See the explanation in [_Interpretable Machine Learning,_ Chapter 5.4.1, Feature Interaction](https://christophm.github.io/interpretable-ml-book/interaction.html#feature-interaction).\n",
        "- See the exploration in this notebook, under the heading ***Example #3: Simple housing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUhq2cjphT6q",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kMW9JbD6wZ28"
      },
      "source": [
        "### Example 1: Predict which waterpumps are functional, just based on location\n",
        "(2 features, non-linear, feature interactions, classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0s7t37euwd41"
      },
      "source": [
        "### Compare a Logistic Regression with 2 features, longitude & latitude ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44TUfQpeo64d",
        "colab": {}
      },
      "source": [
        "train_location = X_train[['longitude', 'latitude']].copy()\n",
        "val_location = X_val[['longitude', 'latitude']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_xIa_1Kozfl",
        "colab": {}
      },
      "source": [
        "# With just long & lat, a Logistic Regression can't beat the majority classifier baseline\n",
        "\n",
        "lr = make_pipeline(\n",
        "    SimpleImputer(),\n",
        "    LogisticRegression(solver='lbfgs', multi_class='auto', n_jobs=-1)\n",
        ")\n",
        "\n",
        "lr.fit(train_location, y_train)\n",
        "print('Logistic Regression:')\n",
        "print('Train Accuracy', lr.score(train_location, y_train))\n",
        "print('Validation Accuracy', lr.score(val_location, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yD31msBkwlVQ"
      },
      "source": [
        "### ... versus a Decision Tree Classifier with 2 features, longitude & latitude\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2RbY4s-vjiMw",
        "colab": {}
      },
      "source": [
        "# With the same 2 features, the Decision Tree's validation accuracy is \n",
        "# almost 10 percentage points better\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = make_pipeline(\n",
        "    SimpleImputer(), \n",
        "    DecisionTreeClassifier(max_depth=16, random_state=42)\n",
        ")\n",
        "\n",
        "dt.fit(train_location, y_train)\n",
        "print('Decision Tree:')\n",
        "print('Train Accuracy', dt.score(train_location, y_train))\n",
        "print('Validation Accuracy', dt.score(val_location, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jFvsu2onNXw7"
      },
      "source": [
        "### Visualize the logistic regression predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt-6_1rOhT65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import itertools\n",
        "from math import floor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def pred_heatmap(model, X, features, class_index=-1, title='', num=100):\n",
        "    \"\"\"\n",
        "    Visualize predicted probabilities, for classifier fit on 2 numeric features\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : scikit-learn classifier, already fit\n",
        "    X : pandas dataframe, which was used to fit model\n",
        "    features : list of strings, column names of the 2 numeric features\n",
        "    class_index : integer, index of class label\n",
        "    title : string, title of plot\n",
        "    num : int, number of grid points for each feature\n",
        "    \"\"\"\n",
        "    feature1, feature2 = features\n",
        "    min1, max1 = X[feature1].min(), X[feature1].max()\n",
        "    min2, max2 = X[feature2].min(), X[feature2].max()\n",
        "    x1 = np.linspace(min1, max1, num)\n",
        "    x2 = np.linspace(max2, min2, num)\n",
        "    combos = list(itertools.product(x1, x2))\n",
        "    y_pred_proba = model.predict_proba(combos)[:, class_index]\n",
        "    pred_grid = y_pred_proba.reshape(num, num).T\n",
        "    table = pd.DataFrame(pred_grid, columns=x1, index=x2)\n",
        "    plot_every_n_ticks = int(floor(num/4))\n",
        "    sns.heatmap(table, # vmin=0, vmax=1, \n",
        "                xticklabels=plot_every_n_ticks, \n",
        "                yticklabels=plot_every_n_ticks)\n",
        "    plt.xlabel(feature1)\n",
        "    plt.ylabel(feature2)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3yeINd4f8bRF",
        "colab": {}
      },
      "source": [
        "pred_heatmap(lr, train_location, features=['longitude', 'latitude'], \n",
        "             class_index=0, title='Logstic Regression, predicted probability, \"functional\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ebepdSHp4X4a",
        "colab": {}
      },
      "source": [
        "pd.Series(lr.named_steps['logisticregression'].coef_[0], \n",
        "          train_location.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lJZSMvW7Nd97"
      },
      "source": [
        "### Visualize the decision tree predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mJ-QtMDK-uX2",
        "colab": {}
      },
      "source": [
        "pred_heatmap(dt, train_location, features=['longitude', 'latitude'], \n",
        "             class_index=0, title='Decision Tree, predicted probability, \"functional\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wdjg7U_jNlJG"
      },
      "source": [
        "### How does a tree grow? Branch by branch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_Jhv0_VId9B",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, HTML\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "for max_depth in [1,2,3]:\n",
        "    \n",
        "    # Fit decision tree\n",
        "    dt = make_pipeline(\n",
        "        SimpleImputer(), \n",
        "        DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    )\n",
        "    dt.fit(train_location, y_train)\n",
        "    \n",
        "    # Display depth & scores\n",
        "    display(HTML(f'Max Depth {max_depth}'))\n",
        "    display(HTML(f'Train Accuracy {dt.score(train_location, y_train):.2f}'))\n",
        "    display(HTML(f'Validation Accuracy {dt.score(val_location, y_val):.2f}'))\n",
        "    \n",
        "    # Plot heatmap of predicted probabilities\n",
        "    pred_heatmap(dt, train_location, features=['longitude', 'latitude'], \n",
        "                 class_index=0, title='Predicted probability, \"functional\"')\n",
        "    \n",
        "    # Plot tree\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "    dot_data = export_graphviz(dt.named_steps['decisiontreeclassifier'], \n",
        "                               out_file=None, \n",
        "                               max_depth=3, \n",
        "                               feature_names=train_location.columns,\n",
        "                               class_names=dt.classes_, \n",
        "                               impurity=False, \n",
        "                               filled=True, \n",
        "                               proportion=True, \n",
        "                               rounded=True)   \n",
        "    display(graphviz.Source(dot_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qm9ta54J66CV",
        "colab": {}
      },
      "source": [
        "for max_depth in range(4,21):\n",
        "    \n",
        "    # Fit decision tree\n",
        "    dt = make_pipeline(\n",
        "        SimpleImputer(), \n",
        "        DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    )\n",
        "    dt.fit(train_location, y_train)\n",
        "    \n",
        "    # Display depth & scores\n",
        "    display(HTML(f'Max Depth {max_depth}'))\n",
        "    display(HTML(f'Train Accuracy {dt.score(train_location, y_train):.2f}'))\n",
        "    display(HTML(f'Validation Accuracy {dt.score(val_location, y_val):.2f}'))\n",
        "    \n",
        "    # Plot heatmap of predicted probabilities\n",
        "    pred_heatmap(dt, train_location, features=['longitude', 'latitude'], \n",
        "                 class_index=0, title='Predicted probability, \"functional\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5zlKegIZBbGr"
      },
      "source": [
        "## Example 2: predicting golf putts\n",
        "(1 feature, non-linear, regression)\n",
        "\n",
        "https://statmodeling.stat.columbia.edu/2008/12/04/the_golf_puttin/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GjvPHk-FBayo",
        "colab": {}
      },
      "source": [
        "columns = ['distance', 'tries', 'successes']\n",
        "data = [[2, 1443, 1346],\n",
        "        [3, 694, 577],\n",
        "        [4, 455, 337],\n",
        "        [5, 353, 208],\n",
        "        [6, 272, 149],\n",
        "        [7, 256, 136],\n",
        "        [8, 240, 111],\n",
        "        [9, 217, 69],\n",
        "        [10, 200, 67],\n",
        "        [11, 237, 75],\n",
        "        [12, 202, 52],\n",
        "        [13, 192, 46],\n",
        "        [14, 174, 54],\n",
        "        [15, 167, 28],\n",
        "        [16, 201, 27],\n",
        "        [17, 195, 31],\n",
        "        [18, 191, 33],\n",
        "        [19, 147, 20],\n",
        "        [20, 152, 24]]\n",
        "\n",
        "putts = pd.DataFrame(columns=columns, data=data)\n",
        "putts['rate of success'] = putts['successes'] / putts['tries']\n",
        "putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tr-83jOEBsxK"
      },
      "source": [
        "#### Compare Linear Regression ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x988kCamBpbn",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "putts_X = putts[['distance']]\n",
        "putts_y = putts['rate of success']\n",
        "lr = LinearRegression()\n",
        "lr.fit(putts_X, putts_y)\n",
        "print('R^2 Score', lr.score(putts_X, putts_y))\n",
        "ax = putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts')\n",
        "ax.plot(putts_X, lr.predict(putts_X));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjLGrZjfFGD-"
      },
      "source": [
        "#### ... versus a Decision Tree Regressor\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EpFIetrsB2yc",
        "colab": {}
      },
      "source": [
        "import graphviz\n",
        "from ipywidgets import interact\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "\n",
        "def viztree(decision_tree, feature_names):\n",
        "    dot_data = export_graphviz(decision_tree, out_file=None, feature_names=feature_names, \n",
        "                               filled=True, rounded=True)   \n",
        "    return graphviz.Source(dot_data)\n",
        "\n",
        "def putts_tree(max_depth=1):\n",
        "    tree = DecisionTreeRegressor(max_depth=max_depth)\n",
        "    tree.fit(putts_X, putts_y)\n",
        "    print('R^2 Score', tree.score(putts_X, putts_y))\n",
        "    ax = putts.plot('distance', 'rate of success', kind='scatter', title='Golf Putts')\n",
        "    ax.step(putts_X, tree.predict(putts_X), where='mid')\n",
        "    plt.show()\n",
        "    display(viztree(tree, feature_names=['distance']))\n",
        "\n",
        "interact(putts_tree, max_depth=(1,6,1));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WBQJB0PVFtIE"
      },
      "source": [
        "## Example 3a: Simple housing \n",
        "(2 features, regression)\n",
        "\n",
        "https://christophm.github.io/interpretable-ml-book/interaction.html#feature-interaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SHQ6oh1uFzHO",
        "colab": {}
      },
      "source": [
        "columns = ['Price', 'Good Location', 'Big Size']\n",
        "\n",
        "data = [[300000, 1, 1], \n",
        "        [200000, 1, 0], \n",
        "        [250000, 0, 1], \n",
        "        [150000, 0, 0]]\n",
        "\n",
        "house = pd.DataFrame(columns=columns, data=data)\n",
        "house"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cH8IVe6GGAsm"
      },
      "source": [
        "#### Compare Linear Regression ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9uMiKdzF6Ud",
        "colab": {}
      },
      "source": [
        "house_X = house.drop(columns='Price')\n",
        "house_y = house['Price']\n",
        "lr = LinearRegression()\n",
        "lr.fit(house_X, house_y)\n",
        "print('R^2', lr.score(house_X, house_y))\n",
        "print('Intercept \\t', lr.intercept_)\n",
        "coefficients = pd.Series(lr.coef_, house_X.columns)\n",
        "print(coefficients.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q7AASlWVGMD4"
      },
      "source": [
        "#### ... versus a Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sWlqO_usGKS8",
        "colab": {}
      },
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "tree.fit(house_X, house_y)\n",
        "print('R^2', tree.score(house_X, house_y))\n",
        "viztree(tree, feature_names=house_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZkaOREUGzYp"
      },
      "source": [
        "## Example 3b: Simple housing, with a twist: _Feature Interaction_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6HE0_pibGzJj",
        "colab": {}
      },
      "source": [
        "house.loc[0, 'Price'] = 400000\n",
        "house_X = house.drop(columns='Price')\n",
        "house_y = house['Price']\n",
        "house"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rh7ZJe7GHCSp"
      },
      "source": [
        "#### Compare Linear Regression ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YYINxJkdG_Q2",
        "colab": {}
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(house_X, house_y)\n",
        "print('R^2', lr.score(house_X, house_y))\n",
        "print('Intercept \\t', lr.intercept_)\n",
        "coefficients = pd.Series(lr.coef_, house_X.columns)\n",
        "print(coefficients.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KIVsFO_HSmS"
      },
      "source": [
        "#### ... versus a Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r6JYZBZBHIX2",
        "colab": {}
      },
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "tree.fit(house_X, house_y)\n",
        "print('R^2', tree.score(house_X, house_y))\n",
        "viztree(tree, feature_names=house_X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49C-XDg1hT7-",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "Decision Trees are useful and powerful for predictive modeling. Try using trees as you continue to participate in the Kaggle challenge!\n",
        "\n",
        "- Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. \n",
        "- Select features. Use a scikit-learn pipeline to encode categoricals, impute missing values, and fit a decision tree classifier.\n",
        "- Get your validation accuracy score.\n",
        "- Get and plot your feature importances.\n",
        "- Submit your predictions to our Kaggle competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvXq76hJhT8C",
        "colab_type": "text"
      },
      "source": [
        "# Sources\n",
        "\n",
        "- A Visual Introduction to Machine Learning\n",
        "  - [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
        "  - [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree â€” by hand â€” to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Letâ€™s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU) â€” _Donâ€™t worry about understanding the code, just get introduced to the concepts. This 10 minute video has excellent diagrams and explanations._\n",
        "- [Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)"
      ]
    }
  ]
}